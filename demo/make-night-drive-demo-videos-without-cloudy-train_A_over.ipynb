{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import torch\n",
    "import shutil\n",
    "import random\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import albumentations.augmentations.transforms as transforms\n",
    "from PIL import Image\n",
    "from predictor import COCODemo\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "from albumentations import Compose\n",
    "from albumentations.pytorch import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify device\n",
    "device = \"cuda\"\n",
    "\n",
    "# specify paths\n",
    "path_to_videos = \"/home/SharedFolder/CurrentDatasets/bdd100k_video_samples\"\n",
    "weights_classification = \"/home/SharedFolder/trained_models/night-drive/weather_classifier/without_cloudy/20190323_ResNet18_without_cloudy_train_A_over/resnet18_weather_classifierbdd100k_sorted_train_A_over_epoch_39.pth\"\n",
    "weights_detection = \"/home/SharedFolder/trained_models/night-drive/detector/20190309_RetinaNet_train_A_over_final_iteration/model_final.pth\"\n",
    "config_file_detection = \"/home/SharedFolder/git/csoehnel/maskrcnn-benchmark/configs/retinanet/retinanet_R-50-FPN_1x_finetune_nightdrive.yaml\"\n",
    "\n",
    "# confidence thresholds, set between 0 and 1 to enable module\n",
    "conf_thresh_detection = 0.7\n",
    "conf_thresh_classification = 0.7\n",
    "\n",
    "# mapping dict for weather predictions\n",
    "dict_weather = {\n",
    "     0: \"Weather: Clear\",\n",
    "     1: \"Weather: Rainy\",\n",
    "     2: \"Weather: Snowy\",        \n",
    "}\n",
    "\n",
    "# for separating temporary folders when using multiple workers\n",
    "worker_name = \"worker1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_train_A_over_C39_0.7_Dfinal_0.7\n"
     ]
    }
   ],
   "source": [
    "outfile_suffix = \"_\" + weights_classification.split(os.sep)[-1].split(\"sorted_\")[-1].split(\"_epoch\")[0]\n",
    "outfile_suffix += \"_C\" + weights_classification.split(\"_epoch_\")[-1].split(\".pth\")[0]\n",
    "outfile_suffix += \"_\" + str(conf_thresh_classification)\n",
    "outfile_suffix += \"_D\" + weights_detection.split(\"model_\")[-1].split(\".pth\")[0]\n",
    "outfile_suffix += \"_\" + str(conf_thresh_detection)\n",
    "print(outfile_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = glob.glob(path_to_videos + \"/*.mov\")\n",
    "random.seed(123)\n",
    "random.shuffle(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weather_classification(weights_weather, dict_weather, device):\n",
    "    # init data transform\n",
    "    transform_weather = Compose([transforms.Resize(height = 224, width = 224), \n",
    "                                 ToTensor(normalize = {\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]})])\n",
    "    # create model\n",
    "    net_weather = models.resnet18(pretrained = True)\n",
    "    # Adaptive Pooling needed for resolutions > 224 x 224\n",
    "    net_weather.avgpool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)), nn.Dropout(p = 0.1))\n",
    "    net_weather.fc = nn.Linear(net_weather.fc.in_features, len(dict_weather))\n",
    "    # send model to device\n",
    "    net_weather.to(torch.device(device))\n",
    "    # load weights\n",
    "    net_weather.load_state_dict(torch.load(weights_weather)[\"model_state_dict\"])\n",
    "    # eval mode, disables dropout, etc.\n",
    "    net_weather.eval()\n",
    "    return net_weather, transform_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_weather(image_bgr, net_weather, dict_weather, transform_weather):\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    with torch.no_grad():\n",
    "        transformed_image = transform_weather(image = image_rgb)[\"image\"]\n",
    "        transformed_image = transformed_image.unsqueeze(0).to(torch.device(device))\n",
    "        prediction_scores = net_weather(transformed_image)\n",
    "        prediction_scores = torch.exp(nn.LogSoftmax(dim = 1)(prediction_scores)).detach().cpu().numpy()\n",
    "        predicted_class = dict_weather[np.argmax(prediction_scores)]\n",
    "        predicted_class_score = np.max(prediction_scores)\n",
    "    return predicted_class, predicted_class_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_detection(weights_detection, config_file_detection, conf_thresh_detection, device):\n",
    "    # specify config file\n",
    "    cfg.merge_from_file(config_file_detection)\n",
    "    # specify model-weight file\n",
    "    cfg.merge_from_list([\"MODEL.WEIGHT\", weights_detection])\n",
    "    cfg.merge_from_list([\"MODEL.DEVICE\", device])\n",
    "    coco_detector = COCODemo(cfg, min_image_size = 800, confidence_threshold = conf_thresh_detection)\n",
    "    return coco_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(image_bgr, coco_detector):\n",
    "    image_bgr = np.array(image_bgr)\n",
    "    # predict\n",
    "    prediction_bgr = coco_detector.run_on_opencv_image(image_bgr, line_width = 3)\n",
    "    return prediction_bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video, net_weather, transform_weather, dict_weather, conf_thresh_classification, coco_detector):\n",
    "    # (re-) create directories for extracted frames and target video\n",
    "    file_name = os.path.basename(video)\n",
    "    path_name = os.path.dirname(video)\n",
    "    temp_path = os.path.join(path_name, worker_name, file_name.split(\".\")[0])\n",
    "    temp_pred_path = os.path.join(temp_path, \"prediction\")\n",
    "    target_path = os.path.join(path_name, \"demovideos\")\n",
    "    target_file = os.path.join(target_path,file_name.split(\".mov\")[0] + outfile_suffix + \".mp4\")\n",
    "    if os.path.isdir(temp_path):\n",
    "        shutil.rmtree(temp_path)\n",
    "    os.makedirs(temp_path, exist_ok = True)\n",
    "    os.makedirs(temp_pred_path, exist_ok = True)\n",
    "    if not os.path.isdir(target_path):\n",
    "        os.makedirs(target_path, exist_ok = True)\n",
    "    elif os.path.exists(target_file):\n",
    "        # do nothing if file already processed\n",
    "        return 0\n",
    "    # extract frames from video\n",
    "    bash_cmd = [\"ffmpeg\", \"-i\", video, \"-start_number\", \"0\", \"-qscale:v\", \"2\", temp_path + \"/frame-%d.jpg\"]\n",
    "    subprocess.call(bash_cmd)\n",
    "    # process frames\n",
    "    frames = glob.glob(temp_path + \"/*.jpg\")\n",
    "    for frame in frames:\n",
    "        # read as bgr\n",
    "        img_bgr = cv2.imread(frame)\n",
    "        # classify weather\n",
    "        pred_weather_class, pred_weather_score = classify_weather(img_bgr, net_weather, dict_weather, transform_weather)\n",
    "        # detect\n",
    "        frame_with_detections_bgr = detect(img_bgr, coco_detector)\n",
    "        # write weather on detection output image\n",
    "        weather_color = [(255, 255, 255) if pred_weather_score >= conf_thresh_classification else (80, 80, 80)]\n",
    "        cv2.putText(frame_with_detections_bgr,\n",
    "                    f\"{pred_weather_class} ({pred_weather_score:.2f})\", \n",
    "                    (5, 715), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.8, \n",
    "                    weather_color[0], \n",
    "                    2)\n",
    "        # write bgr (will be transformed to rgb by open cv)\n",
    "        cv2.imwrite(os.path.join(temp_pred_path, os.path.basename(frame)), \n",
    "                    frame_with_detections_bgr, \n",
    "                    [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "    # construct video\n",
    "    bash_cmd = [\"ffmpeg\", \"-r\", \"30\", \"-f\", \"image2\", \"-i\", temp_pred_path + \"/frame-%d.jpg\", \"-vcodec\", \"libx264\", \"-crf\", \"18\", target_file]\n",
    "    subprocess.call(bash_cmd)\n",
    "    # clean-up\n",
    "    shutil.rmtree(temp_path)\n",
    "    return len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 1 of 1000... done in 331.00s (0.27s / frame)\n",
      "Processing video 2 of 1000... done in 343.93s (0.28s / frame)\n",
      "Processing video 3 of 1000... done in 331.56s (0.28s / frame)\n",
      "Processing video 4 of 1000... done in 170.78s (0.28s / frame)\n",
      "Processing video 5 of 1000... done in 330.09s (0.27s / frame)\n",
      "Processing video 6 of 1000... done in 335.08s (0.28s / frame)\n",
      "Processing video 7 of 1000... done in 341.35s (0.28s / frame)\n",
      "Processing video 8 of 1000... done in 337.62s (0.28s / frame)\n",
      "Processing video 9 of 1000... done in 339.35s (0.28s / frame)\n",
      "Processing video 10 of 1000... done in 334.82s (0.28s / frame)\n",
      "Processing video 11 of 1000... done in 327.97s (0.27s / frame)\n",
      "Processing video 12 of 1000... done in 663.37s (0.28s / frame)\n",
      "Processing video 13 of 1000... done in 336.90s (0.28s / frame)\n",
      "Processing video 14 of 1000... done in 337.28s (0.28s / frame)\n",
      "Processing video 15 of 1000... done in 659.28s (0.27s / frame)\n",
      "Processing video 16 of 1000... done in 340.66s (0.28s / frame)\n",
      "Processing video 17 of 1000... done in 336.30s (0.28s / frame)\n",
      "Processing video 18 of 1000... done in 339.27s (0.28s / frame)\n",
      "Processing video 19 of 1000... done in 336.65s (0.28s / frame)\n",
      "Processing video 20 of 1000... done in 647.78s (0.27s / frame)\n",
      "Processing video 21 of 1000... done in 335.35s (0.28s / frame)\n",
      "Processing video 22 of 1000... done in 334.88s (0.28s / frame)\n",
      "Processing video 23 of 1000... done in 333.42s (0.28s / frame)\n",
      "Processing video 24 of 1000... done in 655.90s (0.27s / frame)\n",
      "Processing video 25 of 1000... done in 336.29s (0.28s / frame)\n",
      "Processing video 26 of 1000... done in 340.44s (0.28s / frame)\n",
      "Processing video 27 of 1000... done in 659.91s (0.27s / frame)\n",
      "Processing video 28 of 1000... done in 336.08s (0.28s / frame)\n",
      "Processing video 29 of 1000... done in 333.82s (0.28s / frame)\n",
      "Processing video 30 of 1000... done in 340.27s (0.28s / frame)\n",
      "Processing video 31 of 1000... done in 664.41s (0.28s / frame)\n",
      "Processing video 32 of 1000... done in 339.82s (0.28s / frame)\n",
      "Processing video 33 of 1000... done in 647.94s (0.27s / frame)\n",
      "Processing video 34 of 1000... done in 335.28s (0.28s / frame)\n",
      "Processing video 35 of 1000... done in 335.53s (0.28s / frame)\n",
      "Processing video 36 of 1000... done in 335.47s (0.28s / frame)\n",
      "Processing video 37 of 1000... done in 335.19s (0.28s / frame)\n",
      "Processing video 38 of 1000... done in 664.74s (0.28s / frame)\n",
      "Processing video 39 of 1000... done in 658.88s (0.27s / frame)\n",
      "Processing video 40 of 1000... done in 656.74s (0.27s / frame)\n",
      "Processing video 41 of 1000... done in 668.63s (0.28s / frame)\n",
      "Processing video 42 of 1000... done in 173.37s (0.28s / frame)\n",
      "Processing video 43 of 1000... done in 340.25s (0.28s / frame)\n",
      "Processing video 44 of 1000... done in 335.04s (0.28s / frame)\n",
      "Processing video 45 of 1000... done in 338.90s (0.28s / frame)\n",
      "Processing video 46 of 1000... done in 665.84s (0.28s / frame)\n",
      "Processing video 47 of 1000... done in 339.17s (0.28s / frame)\n",
      "Processing video 48 of 1000... done in 336.23s (0.28s / frame)\n",
      "Processing video 49 of 1000... done in 652.18s (0.27s / frame)\n",
      "Processing video 50 of 1000... done in 339.08s (0.28s / frame)\n",
      "Processing video 51 of 1000... done in 663.32s (0.28s / frame)\n",
      "Processing video 52 of 1000... done in 335.09s (0.28s / frame)\n",
      "Processing video 53 of 1000... done in 333.98s (0.28s / frame)\n",
      "Processing video 54 of 1000... done in 643.02s (0.27s / frame)\n",
      "Processing video 55 of 1000... done in 341.66s (0.28s / frame)\n",
      "Processing video 56 of 1000... done in 338.80s (0.28s / frame)\n",
      "Processing video 57 of 1000... done in 171.59s (0.28s / frame)\n",
      "Processing video 58 of 1000... done in 669.90s (0.28s / frame)\n",
      "Processing video 59 of 1000... done in 333.34s (0.28s / frame)\n",
      "Processing video 60 of 1000... done in 336.80s (0.28s / frame)\n",
      "Processing video 61 of 1000... done in 657.74s (0.27s / frame)\n",
      "Processing video 62 of 1000... done in 336.38s (0.28s / frame)\n",
      "Processing video 63 of 1000... done in 339.49s (0.28s / frame)\n",
      "Processing video 64 of 1000... done in 170.86s (0.28s / frame)\n",
      "Processing video 65 of 1000... done in 341.69s (0.28s / frame)\n",
      "Processing video 66 of 1000... done in 337.82s (0.28s / frame)\n",
      "Processing video 67 of 1000... done in 335.84s (0.28s / frame)\n",
      "Processing video 68 of 1000... done in 340.16s (0.28s / frame)\n",
      "Processing video 69 of 1000... done in 336.49s (0.28s / frame)\n",
      "Processing video 70 of 1000... done in 335.99s (0.28s / frame)\n",
      "Processing video 71 of 1000... done in 337.00s (0.28s / frame)\n",
      "Processing video 72 of 1000... done in 340.26s (0.28s / frame)\n",
      "Processing video 73 of 1000... done in 335.26s (0.28s / frame)\n",
      "Processing video 74 of 1000... done in 342.58s (0.28s / frame)\n",
      "Processing video 75 of 1000... done in 353.96s (0.29s / frame)\n",
      "Processing video 76 of 1000... done in 334.69s (0.28s / frame)\n",
      "Processing video 77 of 1000"
     ]
    }
   ],
   "source": [
    "# init weather classifier\n",
    "net_weather, transform_weather = init_weather_classification(weights_classification, dict_weather, device)\n",
    "\n",
    "# init detector\n",
    "coco_detector = init_detection(weights_detection, config_file_detection, conf_thresh_detection, device)\n",
    "\n",
    "for i in range(len(videos)):\n",
    "    print(f\"Processing video {i + 1} of {len(videos)}\", end = \"\")\n",
    "    tic = time.time()\n",
    "    n_frames = process_video(videos[i], net_weather, transform_weather, dict_weather, conf_thresh_classification, coco_detector)\n",
    "    toc = time.time()\n",
    "    if n_frames > 0:\n",
    "        print(f\"... done in {toc - tic:.2f}s ({((toc - tic) / n_frames):.2f}s / frame)\")\n",
    "    else:\n",
    "        print(f\"... skipped. File exists.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
